{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieS8yTTTexAd"
   },
   "source": [
    "<h1 align=\"center\">Organization Info</h1> \n",
    "\n",
    "* Дедлайн **DD MM 2018 23:59** для всех групп.\n",
    "* В качестве решения задания нужно прислать ноутбук с подробными комментариями (<span style='color:red'> без присланного решения результат контеста не будет засчитан </span>).\n",
    "* <span style='color:red'>Название команды в контесте должно соответствовать шаблону: НомерГруппы_Имя_Фамилия, например, 594_Ivan_Ivanov</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IFYoJrDvexAf"
   },
   "source": [
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2018_fall_<номер_группы>_<фамилия>``, к примеру -- ``ML2018_fall_495_ivanov``\n",
    "- Выполненное дз сохраните в файл ``<фамилия>_<группа>_task<номер>.ipnb, к примеру`` -- ``ivanov_401_task7.ipnb``\n",
    "\n",
    "**Вопросы**:\n",
    "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2018_fall Question <Содержание вопроса>``\n",
    "\n",
    "\n",
    "--------\n",
    "- **PS1:** Используются автоматические фильтры, и просто не найдем ваше дз, если вы неаккуратно его подпишите.\n",
    "- **PS2:**  Просроченный дедлайн снижает максимальный вес задания по формуле, указнной на первом семинаре\n",
    "- **PS3:** Допустимы исправление кода предложенного кода ниже, если вы считаете"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8tQaNKnyexAh"
   },
   "source": [
    "<h1 align=\"center\">Checking Questions</h1> \n",
    "\n",
    "**Вопрос 1**: Чем LSTM лучше/хуже чем обычная RNN?\n",
    "\n",
    "**Ответ:**\n",
    "На практике обычная RNN хранит информацию только о коротком контексте, т.е. имеет место затухание градиентов. Каждая ячейка LSTM имеет дополнительно и состояние ячейки памяти, что позволяет решить проблему.\n",
    "\n",
    "Из недостатков LSTM - обычная LSTM учитывает только прошлый контекст, двунаправленная учитывает и будущий.\n",
    "\n",
    "В сравнении с \"обычной\" RNN в общем случае - сложность обучения.\n",
    "\n",
    "**Вопрос 2**:  Выпишите производную $\\frac{d c_{n+1}}{d c_{k}}$ для LSTM http://colah.github.io/posts/2015-08-Understanding-LSTMs/, объясните формулу, когда производная затухает, когда взрывается?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**Вопрос 3**: Зачем нужен TBPTT почему BPTT плох?\n",
    "\n",
    "**Ответ:**\n",
    "\n",
    "RNN обычно обучаются с использованием варианта Backpropagation, именуемого Backpropagation Through Time (BPTT).\n",
    "\n",
    "\n",
    "По сути, BPTT разворачивает нейронную сеть и проталкивает градиенты через всю входную последовательность и веса обновляются с накопленными градиентами.\n",
    "\n",
    "BPTT может быть медленным в случае очень длинной входной последовательности. В добавок к скорости работы, накопление градиентов со многих временных шагов (timesteps) может привести к уменьшению значений до нуля или наоборот, к переполнению (взрыву) градиента.\n",
    "\n",
    "Модификация BPTT, ограничивающая число временных шагов, используемых на обратном проходе BP и оценивающая градиент, а не вычисляющая его целиком, называется Truncated Backpropagation Through Time (TBPTT).\n",
    "\n",
    "\n",
    "\n",
    "**Вопрос 4**: Как комбинировать рекуррентные и сверточные сети, а главное зачем? Приведите несколько примеров реальных задач.\n",
    "\n",
    "**Ответ:** Например, когда по картинке нужно построить текстовое описание (pic2seq) http://blog.revolutionanalytics.com/2016/09/deep-learning-part-3.html\n",
    "В кратце, вместо encoder'a seq2seq мы вставили свёрточную нейронную сеть.\n",
    "\n",
    "Другой вариант - когда нужно сгенерировать последовательность (описание, определение текста ...) по аудиозаписи. Аудио можно представлять как спектрограмму (картинку) и действовать аналогично (что-то похожее: http://yerevann.github.io/2016/06/26/combining-cnn-and-rnn-for-spoken-language-identification/#combinations-of-cnn-and-rnn)\n",
    "\n",
    "**Вопрос 5**: Можно ли использовать сверточные сети для классификации текстов? Если нет обоснуйте :D, если да то как? как решить проблему с произвольной длинной входа?\n",
    "\n",
    "**Ответ:**\n",
    "Идея в том, чтобы каким-то образом закодировать символы/слова\n",
    "текста и выделить карты признаков\n",
    "\n",
    "Для символов можно использовать one-hot кодировку:\n",
    "1. пусть имеем m уникальных символов\n",
    "2. пусть l – достаточно большое число символов текста, по которым можно предсказывать его класс\n",
    "3. составим матрицу $m \\times l$\n",
    "4. нарежем её на строки и подадим сети в качестве карт признаков\n",
    "\n",
    "Для слов – эмбеддинги word2vec/GloVe, из которых составляется\n",
    "входная матрица\n",
    "\n",
    "\n",
    "**Вопрос 6**: Attention - что это такое, где применяют и как? Приведите пример использования на какой-нибудь задаче\n",
    "\n",
    "**Ответ:** \n",
    "Аналогично тому, как это происходит у людей, мы пытаемся ввести механизм, позволяющий сосредоточиться на\n",
    "самом важном, т.е. выделить части данных для более детальной обработки\n",
    "\n",
    "Например, это важно для экономии вычислительных ресурсов\n",
    "В случае с переводом позволим декодеру смотреть на эмбеддинги всех слов\n",
    "последовательности и с помощью весов самому выбирать, какие из\n",
    "них важны для генерации очередного слова предложения-перевода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "riiFfBKIexAl"
   },
   "source": [
    "## Grading\n",
    "* starting at zero points\n",
    "* +2 for describing your iteration path in a report below (compare models).\n",
    "* +2 for correct check questions\n",
    "* +3 (7 total) for 99% accuracy with simple NMT model on __TEST__ dataset\n",
    "* +3 (10 total) for 99% accuracy with attention NMT model on __TEST__ dataset\n",
    "----\n",
    "* tatoeba bonus for accuracy on __TEST__ dataset:\n",
    "    * +2 for report\n",
    "    * 60% (14 total)\n",
    "    * 65% (16 total)\n",
    "    * 70% (18 total)\n",
    "    * 75% (20 total)\n",
    "    \n",
    "## Bonus points\n",
    "\n",
    "Common ways to get bonus points are:\n",
    "* Get higher score, obviously.\n",
    "* Anything special about your NN. For example \"A super-small/fast NN that gets 99%\" gets a bonus.\n",
    "* Any detailed analysis of the results. (attention maps, whatever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IeXCYAHbexAn"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TAWI7qJZexAp"
   },
   "outputs": [],
   "source": [
    "# additional packages for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9EytTpY9exAv"
   },
   "outputs": [],
   "source": [
    "# ! pip install faker tqdm babel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NkYBIh5exA0"
   },
   "source": [
    "## Task - translation\n",
    "\n",
    "The machine translation is old and well-known field in natural language processing. From the 1950s scientists tried to create a model to automatically translate from say French to English. Nowadays it became possible and the attention mechanism takes great part in that. Here the example image with attention map for the neural machine translation of sample phrase:\n",
    "<p align=\"center\">\n",
    "  <img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.23.48-PM.png\" width=\"400\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xp69AIDJexA2"
   },
   "source": [
    "In our lab we will concentrate on much simplier task: we will translate from human readable date to machine readable one.\n",
    "\n",
    "To do this we need to get one more concept - Sequence-to-Sequence language modeling.\n",
    "The idea of such architecture is here:\n",
    "<p aling=\"center\">\n",
    "<img src=\"./img/simple_nmt.jpg\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "There is an Embeding layer at the bottom, the RNN in the middle and softmax as an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1604,
     "status": "ok",
     "timestamp": 1525550467264,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "z9tGNB0m5bq3",
    "outputId": "ecdd9537-97d9-4dc3-c7ff-c908527024f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Bidirectional, Dot\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *\n",
    "from keras.layers.merge import Multiply, Concatenate\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "import keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWgAcxj7exA8"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kj_FNqLZexA-"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DiHiJe835brn"
   },
   "source": [
    "Now we need to generate data. It will be dates in different text formats and in fixed output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Lqr3mM4D5bro"
   },
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Pi8idIsn5brw"
   },
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "\n",
    "FORMATS = ['short',\n",
    "           'medium',\n",
    "           'long',\n",
    "           'full',\n",
    "           'd MMM YYY', \n",
    "           'd MMMM YYY',\n",
    "           'dd MMM YYY',\n",
    "           'd MMM, YYY',\n",
    "           'd MMMM, YYY',\n",
    "           'dd, MMM YYY',\n",
    "           'd MM YY',\n",
    "           'd MMMM YYY',\n",
    "           'MMMM d YYY',\n",
    "           'MMMM d, YYY',\n",
    "           'dd.MM.YY']\n",
    "\n",
    "# change this if you want it to work with another language\n",
    "LOCALES = ['en_US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "67qzEjMm5br1"
   },
   "outputs": [],
   "source": [
    "def create_date():\n",
    "    \"\"\"\n",
    "        Creates some fake dates \n",
    "        :returns: tuple containing human readable string, machine readable string, and date object\n",
    "    \"\"\"\n",
    "    dt = fake.date_object()\n",
    "\n",
    "    try:\n",
    "        human_readable = format_date(dt, format=random.choice(FORMATS), locale=random.choice(LOCALES))\n",
    "\n",
    "        case_change = random.choice([0,1,2])\n",
    "        if case_change == 1:\n",
    "            human_readable = human_readable.upper()\n",
    "        elif case_change == 2:\n",
    "            human_readable = human_readable.lower()\n",
    "        # if case_change == 0, do nothing\n",
    "\n",
    "        machine_readable = dt.isoformat()\n",
    "    except AttributeError as e:\n",
    "        return None, None, None\n",
    "\n",
    "    return human_readable, machine_readable, dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "j9eTZ13P5br6"
   },
   "outputs": [],
   "source": [
    "def create_dataset(n_examples):\n",
    "    \"\"\"\n",
    "        Creates a dataset with n_examples and vocabularies\n",
    "        :n_examples: the number of examples to generate\n",
    "    \"\"\"\n",
    "    human_vocab = set()\n",
    "    machine_vocab = set()\n",
    "    dataset = []\n",
    "\n",
    "    for i in tqdm(range(n_examples)):\n",
    "        h, m, _ = create_date()\n",
    "        if h is not None:\n",
    "            dataset.append((h, m))\n",
    "            human_vocab.update(tuple(h))\n",
    "            machine_vocab.update(tuple(m))\n",
    "\n",
    "    human = dict(zip(list(human_vocab) + ['<unk>', '<pad>'], \n",
    "                     list(range(len(human_vocab) + 2))))\n",
    "    inv_machine = dict(enumerate(list(machine_vocab) + ['<unk>', '<pad>']))\n",
    "    machine = {v:k for k,v in inv_machine.items()}\n",
    " \n",
    "    return dataset, human, machine, inv_machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EsQHOc3D5br9"
   },
   "outputs": [],
   "source": [
    "def string_to_int(string, lenght, vocab):\n",
    "    if len(string) > lenght:\n",
    "        string = string[:lenght]\n",
    "        \n",
    "    rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
    "    \n",
    "    if len(string) < lenght:\n",
    "        rep += [vocab['<pad>']] * (lenght - len(string))\n",
    "    \n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MYU62jZi5bsB"
   },
   "outputs": [],
   "source": [
    "def int_to_string(ints, inv_vocab):\n",
    "    return [inv_vocab[i] for i in ints]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTghggDB5bsE"
   },
   "source": [
    "Actually generating data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19418,
     "status": "ok",
     "timestamp": 1525542210085,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "As0XeIDa5bsF",
    "outputId": "57bbf002-418b-4488-ef6a-b68ce5d8ec02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 256046/300000 [00:09<00:01, 25776.92it/s]/home/shevkunov/tensorflow/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "100%|██████████| 300000/300000 [00:11<00:00, 25778.40it/s]\n"
     ]
    }
   ],
   "source": [
    "fake.seed(42)\n",
    "random.seed(42)\n",
    "N = int(3e5)\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = create_dataset(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1525542211301,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "qwN8hGFn23Pt",
    "outputId": "d24d3c82-0ce1-4858-d298-45602ee76ae2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tuesday, september 14, 1971', '1971-09-14')"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ITej2gDY5bsN"
   },
   "outputs": [],
   "source": [
    "# TIME_STEPS is undefined. Set to 20\n",
    "TIME_STEPS = 20 # change me if u want\n",
    "\n",
    "inputs, targets = zip(*dataset)\n",
    "inputs = np.array([string_to_int(i, TIME_STEPS, human_vocab) for i in inputs])\n",
    "targets = [string_to_int(t, TIME_STEPS, machine_vocab) for t in targets]\n",
    "targets = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5R7CxcrZexBy"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = (\n",
    "    inputs[:int(2e5)], targets[:int(2e5)], \n",
    "    inputs[int(2e5):-int(5e4)], targets[int(2e5):-int(5e4)],  \n",
    "    inputs[-int(5e4):], targets[-int(5e4):], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oknUn5iexCI"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TcD33THIexCJ"
   },
   "source": [
    "### Part 1: Simple NMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qWo4x0DM5brd"
   },
   "outputs": [],
   "source": [
    "# :good-enouht:\n",
    "ENCODER_UNITS = 32 # change me if u want\n",
    "DECODER_UNITS = 32 # change me if u want\n",
    "TIME_STEPS = 20 # change me if u want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QQD_Dy8_0MSx"
   },
   "outputs": [],
   "source": [
    "# input - [bs; in_time_len]\n",
    "# output - [bs; out_time_len]; out_time_len=10\n",
    "\n",
    "def model_simple_nmt(in_chars, out_chars):\n",
    "    # RNN encoder -> hidden representation -> RNN decoder\n",
    "    \n",
    "    inputs = Input(shape=(TIME_STEPS,))\n",
    "    \n",
    "    # your code\n",
    "    e = Embedding(in_chars, TIME_STEPS, input_length=TIME_STEPS)(inputs)\n",
    "    encoder_outputs, state_h, state_c = LSTM(ENCODER_UNITS, return_sequences=True, return_state=True)(e)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_outputs,  _,  _ = LSTM(DECODER_UNITS, return_sequences=True, return_state=True)(\n",
    "        e, initial_state=encoder_states\n",
    "    )\n",
    "    d2 = Dense(out_chars)(decoder_outputs)\n",
    "    output = Activation('softmax')(d2)\n",
    "    # your code\n",
    "\n",
    "    model = Model(input=[inputs], output=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1525542247265,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "h8dB6GdrexCb",
    "outputId": "40ee17fd-118f-4143-d65c-846520d6adb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 873,
     "status": "ok",
     "timestamp": 1525542248767,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "ztwvgRe35bsJ",
    "outputId": "153582d2-b000-40cc-8580-1135010e7920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 20, 20)       1200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 20, 32), (No 6784        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 20, 32), (No 6784        embedding_1[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20, 13)       429         lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 20, 13)       0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,197\n",
      "Trainable params: 15,197\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shevkunov/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ac...)`\n"
     ]
    }
   ],
   "source": [
    "m = model_simple_nmt(len(human_vocab), len(machine_vocab))\n",
    "\n",
    "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1525542250232,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "OV_ewY7rZN3g",
    "outputId": "d325f22b-ddd2-45ad-8a2c-0dae01618927"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1443
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 157582,
     "status": "error",
     "timestamp": 1525542408460,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "l_wPSU2t5bsP",
    "outputId": "b83a76d8-69dd-4a29-b1f5-caf9e7e4f221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200000 samples, validate on 50000 samples\n",
      "Epoch 1/10\n",
      "200000/200000 [==============================] - 56s 282us/step - loss: 0.4407 - acc: 0.8492 - val_loss: 0.1594 - val_acc: 0.9489\n",
      "Epoch 2/10\n",
      "200000/200000 [==============================] - 57s 284us/step - loss: 0.0941 - acc: 0.9714 - val_loss: 0.0505 - val_acc: 0.9858\n",
      "Epoch 3/10\n",
      "200000/200000 [==============================] - 56s 282us/step - loss: 0.0356 - acc: 0.9896 - val_loss: 0.0254 - val_acc: 0.9918\n",
      "Epoch 4/10\n",
      "200000/200000 [==============================] - 55s 277us/step - loss: 0.0232 - acc: 0.9920 - val_loss: 0.0214 - val_acc: 0.9923\n",
      "Epoch 5/10\n",
      "200000/200000 [==============================] - 57s 283us/step - loss: 0.0198 - acc: 0.9925 - val_loss: 0.0182 - val_acc: 0.9928\n",
      "Epoch 6/10\n",
      "200000/200000 [==============================] - 55s 276us/step - loss: 0.0182 - acc: 0.9926 - val_loss: 0.0183 - val_acc: 0.9926\n",
      "Epoch 7/10\n",
      "200000/200000 [==============================] - 55s 276us/step - loss: 0.0175 - acc: 0.9927 - val_loss: 0.0168 - val_acc: 0.9929\n",
      "Epoch 8/10\n",
      "200000/200000 [==============================] - 56s 278us/step - loss: 0.0170 - acc: 0.9928 - val_loss: 0.0165 - val_acc: 0.9930\n",
      "Epoch 9/10\n",
      "200000/200000 [==============================] - 56s 279us/step - loss: 0.0168 - acc: 0.9928 - val_loss: 0.0182 - val_acc: 0.9923\n",
      "Epoch 10/10\n",
      "200000/200000 [==============================] - 56s 280us/step - loss: 0.0165 - acc: 0.9928 - val_loss: 0.0160 - val_acc: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b94fb10b8>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(\n",
    "    [X_train], y_train, \n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs=10, batch_size=64, \n",
    "    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "efdw7BVbexC2",
    "outputId": "acd7da40-9723-4898-9774-c158ec90ce08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 110us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.016132847680002452, 0.99296099983215336]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate([X_test], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwYByTjJ5bsS"
   },
   "source": [
    "Lets check our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EIMBnjqY5bsS"
   },
   "outputs": [],
   "source": [
    "EXAMPLES = ['3 May 1979', '5 Apr 09', '20th February 2016', 'Wed 10 Jul 2007']\n",
    "\n",
    "def run_example(model, input_vocabulary, inv_output_vocabulary, text):\n",
    "    encoded = string_to_int(text, TIME_STEPS, input_vocabulary)\n",
    "    prediction = model.predict(np.array([encoded]))\n",
    "    prediction = np.argmax(prediction[0], axis=-1)\n",
    "    return int_to_string(prediction, inv_output_vocabulary)\n",
    "\n",
    "def run_examples(model, input_vocabulary, inv_output_vocabulary, examples=EXAMPLES):\n",
    "    predicted = []\n",
    "    for example in examples:\n",
    "        predicted.append(''.join(run_example(model, input_vocabulary, inv_output_vocabulary, example)))\n",
    "        print('input:', example)\n",
    "        print('output:', predicted[-1])\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 946,
     "status": "ok",
     "timestamp": 1524223952363,
     "user": {
      "displayName": "Sergey Kolesnikov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110932373046251109968"
     },
     "user_tz": -180
    },
    "id": "0cSByOaY5bsW",
    "outputId": "bb237fb8-57d9-429a-fbe9-b654c3c1dcc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 3 May 1979\n",
      "output: 1979-05-03<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "input: 5 Apr 09\n",
      "output: 2009-04-05<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "input: 20th February 2016\n",
      "output: 2016-08-20<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "input: Wed 10 Jul 2007\n",
      "output: 2007-06-10<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1979-05-03<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '2009-04-05<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '2016-08-20<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '2007-06-10<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_examples(m, human_vocab, inv_machine_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9dxpHKlg5bsy"
   },
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BBX4pV_rexDU"
   },
   "source": [
    "### Part 2: All u need is attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zDW4e6j5brg"
   },
   "source": [
    "Here we use more complex idea that simple seq2seq: we're adding two explicit parts of our network - encoder and decoder (which is applied attention on). The explanatory picture for this idea is below:\n",
    "<p aling=\"center\"><img src=\"https://i.stack.imgur.com/Zwsmz.png\"></p>\n",
    "\n",
    "The lower part of the network is encoding the input to some hidden intermediate representation and the upper part is decoing the hidвen represenataion into some readable output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ciiUzsE_exDX"
   },
   "outputs": [],
   "source": [
    "# :good-enouht:\n",
    "ENCODER_UNITS = 32 # change me if u want\n",
    "DECODER_UNITS = 32 # change me if u want\n",
    "TIME_STEPS = 20 # change me if u want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lf40q4rrexDg",
    "outputId": "6f9eda78-e00f-45bb-9bd4-90578bc2cc4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 20)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ckJ3QWe7XYX-"
   },
   "outputs": [],
   "source": [
    "# input - [bs; in_time_len]\n",
    "# output - [bs; out_time_len]; out_time_len=10\n",
    "\n",
    "def model_attention_nmt(in_chars, out_chars):\n",
    "    # RNN encoder -> hidden representation -> RNN decoder\n",
    "    \n",
    "    inputs = Input(shape=(TIME_STEPS,))\n",
    "    \n",
    "    # your code\n",
    "    e = Embedding(in_chars, TIME_STEPS, input_length=TIME_STEPS)(inputs)\n",
    "    encoder_outputs, state_h, state_c = LSTM(ENCODER_UNITS, return_sequences=True, return_state=True)(e)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    f1 = Flatten()(encoder_outputs)\n",
    "    d1 = Dense(DECODER_UNITS)(f1)\n",
    "\n",
    "    f2 = Flatten()(encoder_outputs)\n",
    "    d2 = Dense(DECODER_UNITS)(f2)\n",
    "    \n",
    "    decoder_outputs,  _,  _ = LSTM(DECODER_UNITS, return_sequences=True, return_state=True)(\n",
    "        e, initial_state=[d1, d2]\n",
    "    )\n",
    "    d2 = Dense(out_chars)(decoder_outputs)\n",
    "    output = Activation('softmax')(d2)\n",
    "    # your code\n",
    "\n",
    "    model = Model(input=[inputs], output=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JomdRnhwXfhN",
    "outputId": "b88147b5-293f-4687-c9ee-55b9de297137"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 20, 20)       1200        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 20, 32), (No 6784        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 640)          0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 640)          0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           20512       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           20512       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 20, 32), (No 6784        embedding_2[0][0]                \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 20, 13)       429         lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 20, 13)       0           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 56,221\n",
      "Trainable params: 56,221\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shevkunov/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ac...)`\n"
     ]
    }
   ],
   "source": [
    "m = model_attention_nmt(len(human_vocab), len(machine_vocab))\n",
    "\n",
    "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZI0-cxlIXs_G",
    "outputId": "d7f86bd0-b043-4f9d-cc9e-aed91a56558b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200000 samples, validate on 50000 samples\n",
      "Epoch 1/10\n",
      "200000/200000 [==============================] - 60s 299us/step - loss: 0.5131 - acc: 0.8150 - val_loss: 0.2764 - val_acc: 0.8982\n",
      "Epoch 2/10\n",
      "200000/200000 [==============================] - 59s 295us/step - loss: 0.2161 - acc: 0.9214 - val_loss: 0.1699 - val_acc: 0.9395\n",
      "Epoch 3/10\n",
      "200000/200000 [==============================] - 59s 294us/step - loss: 0.1074 - acc: 0.9635 - val_loss: 0.0587 - val_acc: 0.9821\n",
      "Epoch 4/10\n",
      "200000/200000 [==============================] - 59s 297us/step - loss: 0.0401 - acc: 0.9882 - val_loss: 0.0270 - val_acc: 0.9914\n",
      "Epoch 5/10\n",
      "200000/200000 [==============================] - 61s 303us/step - loss: 0.0234 - acc: 0.9919 - val_loss: 0.0203 - val_acc: 0.9926\n",
      "Epoch 6/10\n",
      "200000/200000 [==============================] - 60s 298us/step - loss: 0.0197 - acc: 0.9924 - val_loss: 0.0188 - val_acc: 0.9928\n",
      "Epoch 7/10\n",
      "200000/200000 [==============================] - 60s 298us/step - loss: 0.0180 - acc: 0.9927 - val_loss: 0.0171 - val_acc: 0.9929\n",
      "Epoch 8/10\n",
      "200000/200000 [==============================] - 60s 299us/step - loss: 0.0174 - acc: 0.9928 - val_loss: 0.0165 - val_acc: 0.9927\n",
      "Epoch 9/10\n",
      "200000/200000 [==============================] - 60s 299us/step - loss: 0.0169 - acc: 0.9928 - val_loss: 0.0180 - val_acc: 0.9925\n",
      "Epoch 10/10\n",
      "200000/200000 [==============================] - 61s 306us/step - loss: 0.0166 - acc: 0.9929 - val_loss: 0.0168 - val_acc: 0.9929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b8d9a0748>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(\n",
    "    [X_train], y_train, \n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs=10, batch_size=64, \n",
    "    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "o8SxEAQEexDq",
    "outputId": "7f5be698-1541-4fea-db5a-940784e27a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 119us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.016827081513293086, 0.99281199943542475]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate([X_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hUeZy7g3Xw9x",
    "outputId": "c133e590-10e0-4a53-d7e8-15f6af652fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 3 May 1979\n",
      "output: 1979-05-03<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "input: 5 Apr 09\n",
      "output: 2009-04-05<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "input: 20th February 2016\n",
      "output: 2016-01-20<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "input: Wed 10 Jul 2007\n",
      "output: 2007-07-13<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1979-05-03<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '2009-04-05<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '2016-01-20<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '2007-07-13<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_examples(m, human_vocab, inv_machine_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YSKXDbZJexDu"
   },
   "source": [
    "### Report\n",
    "\n",
    "* final architectures\n",
    "* comparison\n",
    "* as well as training method and tricks\n",
    "_________________________________________\n",
    "\n",
    "В первом варианте было сделано то, что требовалось - без каких-то идей.\n",
    "\n",
    "Во втором было большой проблемой понять, что вообще нужно, ибо вариаций на тему attention множество, а какая именно требуется, разумеется, не было указано.\n",
    "\n",
    "В итоге был выбран такой вариант:\n",
    "\n",
    "Вместо того, чтобы вернуть decoder последний hidden state, мы учим dense слой принимать все hidden state и делать из них один, который передаётся decoder в качетсве начального. Так мы действительно фокусируемся на каких-то частях предложения. С другой стороны, это не является полноценным attention, но в чате и требовалось написать эту простую версию.\n",
    "\n",
    "Если сравнивать их, то первый вариант учится быстрее (не понятно, случайность это или значимое событие), но итоговое качество у них получилось одинаковое и данная версия attention на этих данных (короткие последовательности) не влияет на результат. (качество и так большое)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "26e8Y7TBexDu"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYIBuN7-exDv"
   },
   "source": [
    "## Part 3*: tatoeba - real NMT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n40y2nfRexDv"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1_HI2hBmexDw"
   },
   "outputs": [],
   "source": [
    "# dataset from http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2626,
     "status": "ok",
     "timestamp": 1525550488995,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "WkQpm2c7exDy",
    "outputId": "bce722df-8a21-4bbb-8bfa-12c7fc58f952"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-05-05 20:01:27--  http://www.manythings.org/anki/rus-eng.zip\r\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2400:cb00:2048:1::6818:6dc4, ...\r\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6366669 (6.1M) [application/zip]\n",
      "Saving to: ‘rus-eng.zip.5’\n",
      "\n",
      "rus-eng.zip.5       100%[===================>]   6.07M  7.68MB/s    in 0.8s    \n",
      "\n",
      "2018-05-05 20:01:28 (7.68 MB/s) - ‘rus-eng.zip.5’ saved [6366669/6366669]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget http://www.manythings.org/anki/rus-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6450,
     "status": "ok",
     "timestamp": 1525550496317,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "-JvpqeaEexD6",
    "outputId": "03b527c2-e2f0-4f46-8e67-2525d7d6b27c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./rus-eng.zip\n",
      "replace rus.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "! unzip ./rus-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KRPArHZ9exD_"
   },
   "outputs": [],
   "source": [
    "with open(\"./rus.txt\") as fin:\n",
    "    data = fin.readlines()\n",
    "data = list(map(lambda x: x.replace(\"\\n\", \"\").lower(), data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 797,
     "status": "ok",
     "timestamp": 1525550501337,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "CZl9OrJGexEC",
    "outputId": "d103690d-788b-4357-95aa-99d439bbea6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300108"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-CroIECFexEM"
   },
   "outputs": [],
   "source": [
    "data = data[:int(1e5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1525550503676,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "0b3ATap9exEP",
    "outputId": "2fa80263-8e6f-4171-bd2d-29b745e0bd05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1525550504803,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "tg79o6vtexEX",
    "outputId": "bd612a43-1a2e-4f64-8391-38be52a0730e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tom is here to see you.\tк тебе том пришёл.\n",
      "tom is here to help us.\tтом здесь, чтобы помочь нам.\n",
      "tom is here to help us.\tтом пришёл нам помочь.\n",
      "tom is having a crisis.\tу тома кризис.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    print(data[-i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkLrsE0nexEd"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uAAGaFgmexEf"
   },
   "outputs": [],
   "source": [
    "source = list(map(lambda x: x.split(\"\\t\")[0], data))\n",
    "target = list(map(lambda x: x.split(\"\\t\")[1], data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AxFnP4LsexEj"
   },
   "outputs": [],
   "source": [
    "source_vocab = set(\"\".join(source).strip())\n",
    "target_vocab = set(\"\".join(target).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VI8irYVFexEn"
   },
   "outputs": [],
   "source": [
    "source_vocab = dict(zip(\n",
    "    list(source_vocab) + ['<unk>', '<pad>'], \n",
    "    list(range(len(source_vocab) + 2))))\n",
    "target_vocab = dict(zip(\n",
    "    list(target_vocab) + ['<unk>', '<pad>'], \n",
    "    list(range(len(target_vocab) + 2))))\n",
    "inv_target_vocab = dict(enumerate(list(target_vocab) + ['<unk>', '<pad>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "F6GQ6TnrexEp"
   },
   "outputs": [],
   "source": [
    "TIME_STEPS = 32\n",
    "ENCODER_UNITS = 128\n",
    "DECODER_UNITS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vTP2xDL3exEq"
   },
   "outputs": [],
   "source": [
    "def model_simple_nmt_tatoeba(in_chars, out_chars):\n",
    "    inputs = Input(shape=(TIME_STEPS,))\n",
    "    \n",
    "    # your code\n",
    "    e = Embedding(in_chars, TIME_STEPS, input_length=TIME_STEPS)(inputs)\n",
    "    \n",
    "    encoder_1, s1, s2, s3, s4 = Bidirectional(LSTM(ENCODER_UNITS, return_sequences=True, return_state=True))(e)\n",
    "    encoder_outputs, s1, s2, s3, s4 = Bidirectional(LSTM(ENCODER_UNITS, return_sequences=True, return_state=True))(\n",
    "        encoder_1, initial_state=[s1, s2, s3, s4]\n",
    "    )\n",
    "\n",
    "    decoder_1, s1, s2, s3, s4 = Bidirectional(LSTM(DECODER_UNITS, return_sequences=True, return_state=True))(\n",
    "        e, initial_state=[s1, s2, s3, s4]\n",
    "    )\n",
    "\n",
    "    decoder_2 = Bidirectional(LSTM(DECODER_UNITS, return_sequences=True, return_state=False))(\n",
    "        decoder_1, initial_state=[s1, s2, s3, s4]\n",
    "    )\n",
    "\n",
    "    d1 = Dense(1024, activation=\"relu\")(decoder_2)\n",
    "    d2 = Dense(out_chars)(d1)\n",
    "    output = Activation('softmax')(d2)\n",
    "    # your code\n",
    "\n",
    "    model = Model(input=[inputs], output=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 733
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2568,
     "status": "ok",
     "timestamp": 1525550564608,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "67ObXmVnexEs",
    "outputId": "05afd3f1-3dc8-4e11-9cd9-9e1cd1ad75d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 32, 32)       1728        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 32, 256), (N 164864      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 32, 256), (N 394240      bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) [(None, 32, 256), (N 164864      embedding_1[0][0]                \n",
      "                                                                 bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 32, 256)      394240      bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_3[0][1]            \n",
      "                                                                 bidirectional_3[0][2]            \n",
      "                                                                 bidirectional_3[0][3]            \n",
      "                                                                 bidirectional_3[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32, 1024)     263168      bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32, 87)       89175       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 87)       0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,472,279\n",
      "Trainable params: 1,472,279\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ac...)`\n"
     ]
    }
   ],
   "source": [
    "m = model_simple_nmt_tatoeba(len(source_vocab), len(target_vocab))\n",
    "\n",
    "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sjURbZMnexEv"
   },
   "outputs": [],
   "source": [
    "inputs = np.array([string_to_int(i, TIME_STEPS, source_vocab) for i in source])\n",
    "targets = [string_to_int(t, TIME_STEPS, target_vocab) for t in target]\n",
    "targets = np.array(list(map(lambda x: to_categorical(x, num_classes=len(target_vocab)), targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pmY0qJ7vhunk"
   },
   "outputs": [],
   "source": [
    "X_test, y_test, X_train, y_train, = (\n",
    "    inputs[:int(1e4)], targets[:int(1e4)], \n",
    "    inputs[int(1e4):], targets[int(1e4):]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5477531,
     "status": "ok",
     "timestamp": 1525556057203,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "CakhMoaqexEx",
    "outputId": "2cbcaaa7-57b8-4dea-86e0-84bc057a2337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "43840/90000 [=============>................] - ETA: 7:37 - loss: 2.1983 - acc: 0.444690000/90000 [==============================] - 914s 10ms/step - loss: 2.1073 - acc: 0.4636 - val_loss: 1.4210 - val_acc: 0.6405\n",
      "Epoch 2/6\n",
      "90000/90000 [==============================] - 912s 10ms/step - loss: 1.8898 - acc: 0.5105 - val_loss: 1.3439 - val_acc: 0.6570>.] - ETA: 0s - loss: 1.8898 - acc: 0.510\n",
      "Epoch 3/6\n",
      "20672/90000 [=====>........................] - ETA: 11:22 - loss: 1.8067 - acc: 0.527390000/90000 [==============================] - 912s 10ms/step - loss: 1.7733 - acc: 0.5340 - val_loss: 1.2875 - val_acc: 0.6673\n",
      "Epoch 4/6\n",
      "90000/90000 [==============================] - 910s 10ms/step - loss: 1.6881 - acc: 0.5491 - val_loss: 1.2541 - val_acc: 0.6744>.] - ETA: 0s - loss: 1.6881 - acc: 0.549\n",
      "Epoch 5/6\n",
      "20672/90000 [=====>........................] - ETA: 11:21 - loss: 1.6249 - acc: 0.559690000/90000 [==============================] - 910s 10ms/step - loss: 1.6181 - acc: 0.5609 - val_loss: 1.2277 - val_acc: 0.6788\n",
      "Epoch 6/6\n",
      "90000/90000 [==============================] - 912s 10ms/step - loss: 1.5603 - acc: 0.5710 - val_loss: 1.2094 - val_acc: 0.6824>.] - ETA: 0s - loss: 1.5603 - acc: 0.571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc04658be10>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(\n",
    "    [X_train], y_train, \n",
    "    epochs=6, batch_size=64, \n",
    "    validation_data=(X_test, y_test),\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2741558,
     "status": "ok",
     "timestamp": 1525559145013,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "sQW37YH8PxjS",
    "outputId": "82dcd952-9641-4767-fa51-2516357f587a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "43904/90000 [=============>................] - ETA: 7:32 - loss: 1.5110 - acc: 0.579690000/90000 [==============================] - 909s 10ms/step - loss: 1.5092 - acc: 0.5798 - val_loss: 1.1986 - val_acc: 0.6845\n",
      "Epoch 2/3\n",
      "90000/90000 [==============================] - 918s 10ms/step - loss: 1.4656 - acc: 0.5874 - val_loss: 1.1993 - val_acc: 0.6833>.] - ETA: 0s - loss: 1.4655 - acc: 0.587\n",
      "Epoch 3/3\n",
      "20672/90000 [=====>........................] - ETA: 11:28 - loss: 1.4165 - acc: 0.596790000/90000 [==============================] - 914s 10ms/step - loss: 1.4265 - acc: 0.5943 - val_loss: 1.1954 - val_acc: 0.6864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc02403a208>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(  \n",
    "    [X_train], y_train, \n",
    "    epochs=3, batch_size=64, \n",
    "    validation_data=(X_test, y_test),\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52654,
     "status": "ok",
     "timestamp": 1525556109913,
     "user": {
      "displayName": "Кирилл Сергеевич Шевкунов",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "114659157788966761059"
     },
     "user_tz": -180
    },
    "id": "JYtgnOmrhuns",
    "outputId": "f04e19d0-e574-4bfb-9b64-a29fee899138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 52s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2094164043426514, 0.6824]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate([X_test], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbkM69wzexE6"
   },
   "source": [
    "### Tatoeba Report\n",
    "\n",
    "* final architectures\n",
    "* comparison\n",
    "* as well as training method and tricks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "auxV6OOprKz0"
   },
   "source": [
    "Just copy previous solution - loss: 1.5730 - acc: 0.5765 - val_loss: 2.1012 - val_acc: 0.4484\n",
    "_____________________________________________________________________________________________\n",
    "\n",
    "    # your code\n",
    "    e = Embedding(in_chars, TIME_STEPS, input_length=TIME_STEPS)(inputs)\n",
    "    encoder_outputs, s1, s2, s3, s4 = Bidirectional(LSTM(ENCODER_UNITS, return_sequences=True, return_state=True))(e)\n",
    "    \n",
    "    \"\"\"\n",
    "    f = Flatten()(encoder_outputs)\n",
    "    d = Dense(DECODER_UNITS)(f)\n",
    "\n",
    "    f2 = Flatten()(encoder_outputs)\n",
    "    d2 = Dense(DECODER_UNITS)(f2)\n",
    "    \n",
    "    f3 = Flatten()(encoder_outputs)\n",
    "    d3 = Dense(DECODER_UNITS)(f3)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    decoder_outputs = Bidirectional(LSTM(DECODER_UNITS, return_sequences=True, return_state=False))(\n",
    "        e, initial_state=[s1, s2, s3, s4]\n",
    "    )\n",
    "\n",
    "\n",
    "    d2 = Dense(out_chars)(decoder_outputs)\n",
    "    output = Activation('softmax')(d2)\n",
    "    # your code\n",
    "    \n",
    " loss: 1.3960 - acc: 0.6068 - val_loss: 2.0059 - val_acc: 0.4620\n",
    " ____________________________________________________________________________________________\n",
    " \n",
    "     # your code\n",
    "    e = Embedding(in_chars, TIME_STEPS, input_length=TIME_STEPS)(inputs)\n",
    "    encoder_outputs, s1, s2, s3, s4 = Bidirectional(LSTM(ENCODER_UNITS, return_sequences=True, return_state=True))(e)\n",
    "    \n",
    "\n",
    "    f = Flatten()(encoder_outputs)\n",
    "    d = Dense(DECODER_UNITS)(f)\n",
    "\n",
    "    f2 = Flatten()(encoder_outputs)\n",
    "    d2 = Dense(DECODER_UNITS)(f2)\n",
    "    \n",
    "    decoder_outputs = LSTM(DECODER_UNITS, return_sequences=True, return_state=False)(\n",
    "        e, initial_state=[d, d2]\n",
    "    )\n",
    "\n",
    "\n",
    "    d2 = Dense(out_chars)(decoder_outputs)\n",
    "    output = Activation('softmax')(d2)\n",
    "    # your code\n",
    " \n",
    " loss: 1.5674 - acc: 0.5782 - val_loss: 2.0963 - val_acc: 0.4508\n",
    " _____________________________________________________________________________________________\n",
    "    \n",
    "    # your code\n",
    "    e = Embedding(in_chars, TIME_STEPS, input_length=TIME_STEPS)(inputs)\n",
    "    \n",
    "    encoder_1, s1, s2, s3, s4 = Bidirectional(LSTM(ENCODER_UNITS, return_sequences=True, return_state=True))(e)\n",
    "    encoder_outputs, s1, s2, s3, s4 = Bidirectional(LSTM(ENCODER_UNITS, return_sequences=True, return_state=True))(\n",
    "        encoder_1, initial_state=[s1, s2, s3, s4]\n",
    "    )\n",
    "\n",
    "    decoder_1, s1, s2, s3, s4 = Bidirectional(LSTM(DECODER_UNITS, return_sequences=True, return_state=True))(\n",
    "        e, initial_state=[s1, s2, s3, s4]\n",
    "    )\n",
    "\n",
    "    decoder_2 = Bidirectional(LSTM(DECODER_UNITS, return_sequences=True, return_state=False))(\n",
    "        decoder_1, initial_state=[s1, s2, s3, s4]\n",
    "    )\n",
    "\n",
    "    d1 = Dense(1024, activation=\"relu\")(decoder_2)\n",
    "    d2 = Dense(out_chars)(d1)\n",
    "    output = Activation('softmax')(d2)\n",
    "    # your code\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wkSMo4G4exE7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Copy of colab_nmt_dates_tatoeba.ipynb",
   "provenance": [
    {
     "file_id": "1z9e6o_GHG0ZkmwIYSnw9wrLkrscxEp_w",
     "timestamp": 1525548796216
    },
    {
     "file_id": "1Xtn4UTJOeQ999g78urAnPaZgboio8dz5",
     "timestamp": 1524199403566
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
